{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "import tarfile\n",
    "from io import StringIO\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if the following files exists\n",
      "['cifar10\\\\cifar-10-batches-py\\\\meta_data', 'cifar10\\\\cifar-10-batches-py\\\\data_batch_1', 'cifar10\\\\cifar-10-batches-py\\\\data_batch_2', 'cifar10\\\\cifar-10-batches-py\\\\data_batch_3', 'cifar10\\\\cifar-10-batches-py\\\\data_batch_4', 'cifar10\\\\cifar-10-batches-py\\\\data_batch_5', 'cifar10\\\\cifar-10-batches-py\\\\test_batch']\n",
      "\n",
      "Extracting cifar10\\cifar-10-python.tar.gz\n",
      "Unable to find the file cifar10\\cifar-10-python.tar.gz\n",
      "Downloading CIFAR-10 from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "Detected data size: 170498071KB\n",
      "Making a directory cifar-10 to store data\n",
      "Downloading data\n",
      "..........................."
     ]
    }
   ],
   "source": [
    "def download_cifar10(url):\n",
    "    f = os.path.join('cifar10', \"cifar-10-python.tar.gz\")\n",
    "    try:\n",
    "        files = [\n",
    "            os.path.join('cifar10', 'cifar-10-batches-py', 'meta_data'),\n",
    "            os.path.join('cifar10', 'cifar-10-batches-py', 'data_batch_1'),\n",
    "            os.path.join('cifar10', 'cifar-10-batches-py', 'data_batch_2'),\n",
    "            os.path.join('cifar10', 'cifar-10-batches-py', 'data_batch_3'),\n",
    "            os.path.join('cifar10', 'cifar-10-batches-py', 'data_batch_4'),\n",
    "            os.path.join('cifar10', 'cifar-10-batches-py', 'data_batch_5'),\n",
    "            os.path.join('cifar10', 'cifar-10-batches-py', 'test_batch')\n",
    "        ]\n",
    "        print('Checking if the following files exists\\n{}\\n'.format(files))\n",
    "        \n",
    "        assert_msg = 'Some of the files were missing'\n",
    "        assert all([os.path.exists(path) for path in files]), assert_msg\n",
    "    except:\n",
    "        try:\n",
    "            print(\"Extracting {}\".format(f))\n",
    "            filename = os.path.join('cifar10', f)\n",
    "            tar = tarfile.open(f, \"r:gz\")\n",
    "            tar.extractall('cifar10')\n",
    "            tar.close()\n",
    "        except FileNotFoundError:\n",
    "            print(\"Unable to find the file {}\".format(f))\n",
    "            print('Downloading CIFAR-10 from {}'.format(url))\n",
    "            res = requests.get(url, stream=True)\n",
    "            total_length = int(res.headers.get('content-length'))\n",
    "            print('Detected data size: {}KB'.format(total_length))\n",
    "            print('Making a directory cifar-10 to store data')\n",
    "            if not os.path.exists('cifar10'):\n",
    "                os.mkdir('cifar10')\n",
    "            with open(f, 'wb') as f:\n",
    "                print('Downloading data')\n",
    "                for data in res.iter_content(chunk_size=1024*1024):\n",
    "                    print('.',end='')\n",
    "                    f.write(data)\n",
    "            \n",
    "            print(\"Extracting {}\".format(f))\n",
    "            filename = os.path.join('cifar10', f)\n",
    "            tar = tarfile.open(f, \"r:gz\")\n",
    "            tar.extractall('cifar10')\n",
    "            tar.close()\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "        \n",
    "    print('\\n\\tDone')\n",
    "    \n",
    "download_cifar10('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few helper functions for processing images \n",
    "* `vec2image` - Takes in a vector of 3072 elements, reshap it to 32x32x3, subtract the mean and optionally flip the image\n",
    "* `get_image` - Given a single class gets an image (for visual inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2image(image_vec, normalize=False, global_mean=None, flip=False):\n",
    "    \"\"\" Creating a 2D image from the 1D vector in the data \"\"\"\n",
    "    assert image_vec.size == 3072, \"This (shape:{}) is not a CIFAR-10 Image\".format(image_vec.shape)\n",
    "    img_mat = image_vec.reshape(32,32,3, order='F')\n",
    "    img_mat = np.rot90(img_mat,3)\n",
    "    if normalize and global_mean:\n",
    "        img_mat = img_mat.astype(np.float32) - global_mean\n",
    "    if flip:\n",
    "        img_mat = np.flip(img_mat, axis=1)\n",
    "    return img_mat\n",
    "\n",
    "def get_image(file, class_label):\n",
    "    \"\"\" Given a class get an image \"\"\"\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    \n",
    "    for image_vec, label in zip(dict[b\"data\"], dict[b\"labels\"]):\n",
    "        if label==class_label:\n",
    "            img_mat = vec2image(image_vec)\n",
    "            return img_mat\n",
    "        else:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def get_label_to_name_map(file):\n",
    "    \"\"\" Get a list of label names in the data \"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        label_dict = pickle.load(f, encoding='bytes')\n",
    "        return [str(v,'utf-8') for v in label_dict[b\"label_names\"]]\n",
    "    \n",
    "    return None\n",
    "\n",
    "# file batches.meta for label to string map\n",
    "label_map = get_label_to_name_map(os.path.join('cifar10', 'cifar-10-batches-py', 'batches.meta'))\n",
    "\n",
    "plt.subplots(2,5)\n",
    "for cls in range(10):\n",
    "    img = get_image(os.path.join('cifar10', 'cifar-10-batches-py', 'data_batch_1'), cls)\n",
    "    plt.subplot(2,5,cls+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(label_map[cls])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Keras graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "\n",
    "# TODO: Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "* Using `train_on_batch` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('cifar10','cifar-10-batches-py')\n",
    "n_classes = 10\n",
    "batch_size = 32\n",
    "\n",
    "train_file_list = [\n",
    "    os.path.join(data_dir, f) \\\n",
    "    for f in ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "]\n",
    "test_file_list = [os.path.join(data_dir, 'test_batch')]\n",
    "\n",
    "for ep in range(20):\n",
    "    losses = []\n",
    "    accuracy = []\n",
    "    for f in train_file_list:\n",
    "\n",
    "        with open(f, 'rb') as fo:\n",
    "            # labels, data\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "            part_vec2image = partial(\n",
    "                vec2image, normalize=True, global_mean=np.mean(dict[b\"data\"])\n",
    "            )\n",
    "\n",
    "\n",
    "            \" Going through each batch in the data file\"\n",
    "            for di in range(len(dict[b\"labels\"])//batch_size):\n",
    "                # Defining random indices\n",
    "                rand_idx = np.random.randint(\n",
    "                    0, len(dict[b\"labels\"]), batch_size\n",
    "                )\n",
    "            \n",
    "                # Creating onehot labels from class labels\n",
    "                batch_one_hot = np.zeros(shape=(batch_size, n_classes))\n",
    "                batch_one_hot[\n",
    "                    np.arange(batch_size), np.array(dict[b\"labels\"])[rand_idx]\n",
    "                ] = 1.0\n",
    "\n",
    "                # Creating a batch of images\n",
    "                batch_images = np.apply_along_axis(\n",
    "                    part_vec2image, axis=1, arr=dict[b\"data\"][rand_idx,:]\n",
    "                )\n",
    "                \n",
    "                # TODO: Save a set of normalized images\n",
    "\n",
    "                # Training the CNN on batch of images\n",
    "                # TODO: Train the model on a single batch\n",
    "\n",
    "                # TODO: Evaluate the model\n",
    "\n",
    "                losses.append(loss)\n",
    "                accuracy.append(acc)\n",
    "        print('Loss for epoch: {}'.format(np.mean(losses)))\n",
    "        print('Train accuracy for epoch: {}'.format(np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "* Using `fit` function with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
