{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow\n",
    "Estimated time: 1:30 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Checking if a GPU is available\n",
    "try:\n",
    "    assert tf.test.is_gpu_available()\n",
    "except:\n",
    "    raise AssertionError(\"A GPU was not detected. If your computer does not have a GPU, ignore this message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good old Python vs TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.69 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "614 ms ± 13 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Numpy took 5.7x times more time than TensorFlow\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "mat_size = 5000\n",
    "def numpy_dot(a,b):\n",
    "    return np.dot(a,b)\n",
    "\n",
    "def tf_dot(a,b):\n",
    "    tf_a = tf.placeholder(shape=[mat_size, mat_size], dtype=tf.float32, name='a')\n",
    "    tf_b = tf.placeholder(shape=[mat_size, mat_size], dtype=tf.float32, name='b')\n",
    "    with tf.Session() as sess:\n",
    "        return sess.run(tf.matmul(tf_a,tf_b), feed_dict={tf_a: a, tf_b: b})\n",
    "    \n",
    "# Python doing a dot product\n",
    "a = np.random.rand(mat_size, mat_size)\n",
    "b = np.random.rand(mat_size, mat_size)\n",
    "\n",
    "np_time = %timeit -o numpy_dot(a,b)\n",
    "tf_time = %timeit -o tf_dot(a,b)\n",
    "\n",
    "print(\"Numpy took {:.1f}x times more time than TensorFlow\".format(np_time.best*1.0/tf_time.best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy is very slow (for large matrices)\n",
    "\n",
    "Not just matrix multiplication, but also other operations like convolution which are ubiquotous in neural networks. This is where TensorFlow fits in. Tensorflow has highly GPU-optimized CUDA kernels for these operations which allows TensorFlow to exploit the parallel computation power of GPUs. Where a very good CPU might be able to run 128 threads (vectorized and hyper-threaded) simultaneously, NVIDIA GTX 1080 has 2560 cores.\n",
    "\n",
    "matrix multiplication parallel image\n",
    "\n",
    "## Why use TensorFlow?\n",
    "\n",
    "> TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.\n",
    "\n",
    "* Efficiently leverages the explicit parallel nature of GPUs to perform parallelizable computations quickly\n",
    "* Has almost all the high-level functions you will need to implement simple or complex neural network\n",
    "* Provides automatic differentiation so you don't have to write the backward pass of neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving head-first into TensorFlow\n",
    "\n",
    "Here we will be diving into TensorFlow specifics\n",
    "\n",
    "## 1.1. Placeholders, variables, tensors and operations\n",
    "\n",
    "Here you will be learning about placeholders, variables, tensors and operations.\n",
    "* Placeholder: A type of tensor where data is fed at run time\n",
    "* Variable: A type of tensor which is mutable, of which value can be changed later\n",
    "* Tensor: An immutable tensor that cannot be changed ones initialized\n",
    "* Operation: Performs transformations on various tensors to produce new outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'a' is a Placeholder\n",
      "'b' is a VariableV2\n",
      "'c' is a Const\n",
      "'d' is a <function add at 0x0000022E95AC8620>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.placeholder(name='a', shape=[5,10], dtype=tf.float32)\n",
    "print(\"\\'{}\\' is a {}\".format('a',a.op.type))\n",
    "b = tf.get_variable(name='b', shape=[5,10], initializer=tf.initializers.random_normal(), dtype=tf.float32)\n",
    "print(\"\\'{}\\' is a {}\".format('b',b.op.type))\n",
    "c = tf.convert_to_tensor(np.ones(shape=(5,10),dtype=np.float32))\n",
    "print(\"\\'{}\\' is a {}\".format('c',c.op.type))\n",
    "d = tf.add\n",
    "print(\"\\'{}\\' is a {}\".format('d',d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_c => placeholder (shape 2x1, dtype float32)\n",
    "# tf_d => variable (shape 3x2, dtype float32)\n",
    "# tf_op => tf.matmul(tf_d, tf_c)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf_c = tf.placeholder(name='c', shape=[2,1], dtype=tf.float32)\n",
    "tf_d = tf.get_variable(\n",
    "    name='d', shape=[3,2], dtype=tf.float32,\n",
    "    initializer=tf.random_normal_initializer()\n",
    "                      )\n",
    "tf_op = tf.matmul(tf_d, tf_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Using placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a ([1]) + 4 = [5.]\n",
      "a ([2]) + 4 = [6.]\n",
      "a ([3]) + 4 = [7.]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: Define a placeholder tf_a which has shape [1] and type float32\n",
    "\n",
    "tf_add_ab = tf.add(tf_a, 4, name='add')\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    for a in [[1],[2],[3]]:\n",
    "        a_plus_b = sess.run(tf_add_ab, feed_dict={tf_a:a})\n",
    "        print(\"a ({}) + 4 = {}\".format(a, a_plus_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Using variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = ([2.]) (before updating)\n",
      "a = ([3.]) (after updating)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: Define a variable tf_a which has shape [1], type float32 and initialized with constant_initializer having value 2\n",
    "\n",
    "tf_update_a = tf.assign(tf_a, [3])\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(init)\n",
    "    a = sess.run(tf_a)\n",
    "    a_updated = sess.run(tf_update_a)\n",
    "    print(\"a = ({}) (before updating)\".format(a))\n",
    "    print(\"a = ({}) (after updating)\".format(a_updated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Using operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 8\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:    \n",
    "    \n",
    "    # TODO: Define an operation that adds 3 and 5 together and assign it to tf_a_plus_b\n",
    "    \n",
    "    a = sess.run(tf_a_plus_b)\n",
    "    print(\"a = {}\".format(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we run a Python program\n",
    "\n",
    "When you write a normal python program it is *defined-by-run*, meaning the lines will be executed immediately as they are called by the interpreter. And if you have any loops changing a single variable within the loop, the variable will be overidden by the value produced in the current iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have to save 1000 weeks in order to by a House\n",
      "You have to save 50 weeks in order to by a Car\n",
      "You have to save 5 weeks in order to by a Desktop-DL\n"
     ]
    }
   ],
   "source": [
    "saving_per_week = 1000\n",
    "dreams = [(\"House\", 1000000), (\"Car\", 50000), (\"Desktop-DL\", 5000)]\n",
    "\n",
    "# TODO: For each dream compute how many weeks you need to save money\n",
    "for item, price in dreams:\n",
    "    num_week = price/saving_per_week\n",
    "    print(\n",
    "        'You have to save {} weeks in order to by a {}'.format(\n",
    "        int(num_week), item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dreams', 'exit', 'get_ipython', 'item', 'np', 'num_week', 'price', 'quit', 'saving_per_week']\n"
     ]
    }
   ],
   "source": [
    "print([v for v in dir() if (not v.startswith('_')) and (not v.startswith('tf')) and v!='In' and v!='Out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try this with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have to save 1000 weeks in order to by a House\n",
      "You have to save 50 weeks in order to by a Car\n",
      "You have to save 5 weeks in order to by a Desktop-DL\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "saving_per_week = 1000\n",
    "dreams = [(\"House\", 1000000), (\"Car\", 50000), (\"Desktop-DL\", 5000)]\n",
    "\n",
    "# TODO: Use tf.get_variable and tf ops to compute how many weeks need to be saved for each dream\n",
    "with tf.Session() as sess:\n",
    "    for item, price in dreams:\n",
    "        # tf_num_weeks => tf.get_variable\n",
    "        tf_num_weeks = tf.Variable(\n",
    "            price/saving_per_week,\n",
    "            name='num_weeks', dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        num_weeks = sess.run(tf_num_weeks)\n",
    "        print(\n",
    "        'You have to save {} weeks in order to by a {}'.format(\n",
    "        int(num_weeks), item))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in the graph\n",
      "['num_weeks:0', 'num_weeks_1:0', 'num_weeks_2:0']\n",
      "\n",
      "Operations in the graph\n",
      "['num_weeks/initial_value', 'num_weeks', 'num_weeks/Assign', 'num_weeks/read', 'init', 'num_weeks_1/initial_value', 'num_weeks_1', 'num_weeks_1/Assign', 'num_weeks_1/read', 'init_1', 'num_weeks_2/initial_value', 'num_weeks_2', 'num_weeks_2/Assign', 'num_weeks_2/read', 'init_2']\n"
     ]
    }
   ],
   "source": [
    "print(\"Variables in the graph\")\n",
    "print([v.name for v in tf.global_variables()])\n",
    "print(\"\\nOperations in the graph\")\n",
    "print([op.name for op in tf.get_default_graph().get_operations()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh oooh ... a TensorFlow program is different...\n",
    "\n",
    "A TensorFlow programs use graph based execution. That is, they first build a graph and then do computations over and over again on the graph with different inputs. A TensorFlow graph is like a [Galton board](https://en.wikipedia.org/wiki/Bean_machine). Your input can change (the small balls) but the screws/pegs stay fixed. And depending on how you drop the ball, the output (i.e. the bin it falls to) will be differnt.\n",
    "\n",
    "![Galton board](../images/galton_board.png)\n",
    "\n",
    "## 1.2. Writing a TensorFlow program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have to save 1000 weeks in order to by a House,1000000.0\n",
      "You have to save 50 weeks in order to by a Car,50000.0\n",
      "You have to save 5 weeks in order to by a Desktop-DL,5000.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "saving_per_week = 1000\n",
    "dreams = [(\"House\", 1000000), (\"Car\", 50000), (\"Desktop-DL\", 5000)]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \"\"\" Defining Graph \"\"\"\n",
    "    \n",
    "    # TODO: Define a placeholder tf_price that has shape None, type int32 and name tf_price\n",
    "    tf_price = tf.placeholder(\n",
    "        name='price', shape=[], dtype=tf.float32)\n",
    "    tf_x = tf.placeholder()\n",
    "    # TODO: Define an operation divide which divides tf_price by saving_per_week and call it num_weeks, and assign to tf_num_weeks\n",
    "    tf_num_weeks = tf_price/saving_per_week\n",
    "    \n",
    "    \"\"\" Executing the Graph \"\"\"\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #tf.global_variables_initializer().run()\n",
    "    \n",
    "    for item, price in dreams:\n",
    "        \n",
    "        # TODO: Get the number of weeks by executing tf_num_weeks with correct value for tf_price placeholder and assign it to \"weeks\"\n",
    "        weeks, new_price = sess.run(\n",
    "            [tf_num_weeks,tf_price], \n",
    "            feed_dict={tf_price:price, tf_x:xx}\n",
    "        )\n",
    "        print(\"You have to save {:d} weeks in order to by a {},{}\".format(\n",
    "            int(weeks), item, new_price)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Trivia: What would be the following variable's name in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.get_variable('b', initializer=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Scoping variables\n",
    "\n",
    "Scoping is context managing for variables. With scopes you are essentially putting variables in different scopes, and retrieve them from the correct scope when you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who let those variables out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My house price is 580000\n",
      "\n",
      "Variables in the graph\n",
      "['n_beds:0', 'area:0', 'has_park:0']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: Create tf_n_beds (3), tf_area (100), tf_has_park (1) variables with the initial value within brackets\n",
    "#       using tf.Variable. Then compute the house price using\n",
    "#       10000* tf_n_beds + 5000 * tf_area + 50000 * tf_has_park\n",
    "def compute_house_price():\n",
    "    \"\"\" Computing house price using number of beds, area and has a park\"\"\"\n",
    "    tf_n_beds = tf.Variable(3, name='n_beds')\n",
    "    tf_area = tf.Variable(100, name='area')\n",
    "    tf_has_park = tf.Variable(1, name='has_park')\n",
    "    \n",
    "    return 10000*tf_n_beds + \\\n",
    "            5000 * tf_area + \\\n",
    "            50000 * tf_has_park\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    tf_house_price = compute_house_price()\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('My house price is {}'.format(sess.run(tf_house_price)))\n",
    "    print(\"\\nVariables in the graph\")\n",
    "    print([v.name for v in tf.global_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "My house price is 580000\n",
      "\n",
      "Variables in the graph\n",
      "['n_beds:0', 'area:0', 'has_park:0', 'n_beds_1:0', 'area_1:0', 'has_park_1:0', 'n_beds_2:0', 'area_2:0', 'has_park_2:0', 'n_beds_3:0', 'area_3:0', 'has_park_3:0', 'n_beds_4:0', 'area_4:0', 'has_park_4:0', 'n_beds_5:0', 'area_5:0', 'has_park_5:0', 'n_beds_6:0', 'area_6:0', 'has_park_6:0', 'n_beds_7:0', 'area_7:0', 'has_park_7:0', 'n_beds_8:0', 'area_8:0', 'has_park_8:0', 'n_beds_9:0', 'area_9:0', 'has_park_9:0']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    for _ in range(10):\n",
    "\n",
    "        # TODO: call the compute_house_price 10 times in this loop\n",
    "        tf_house_price = compute_house_price()\n",
    "        tf.global_variables_initializer().run()\n",
    "        print('My house price is {}'.format(sess.run(tf_house_price)))\n",
    "        \n",
    "    print(\"\\nVariables in the graph\")\n",
    "    \n",
    "    #TODO: Print the variables in the graph\n",
    "    print([v.name for v in tf.global_variables()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Scoping\n",
    "Scoping provides you protection against creating redundant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "My house price is 580000.0\n",
      "\n",
      "Variables in the graph\n",
      "['house/n_beds:0', 'house/area:0', 'house/has_park:0']\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# TODO: Create tf_n_beds (3), tf_area (100), tf_has_park (1) variables with the initial value within brackets\n",
    "# using tf.get_variable (use initializer keyword argument to specify the initial value). \n",
    "# Then compute the house price using\n",
    "# 10000* tf_n_beds + 5000 * tf_area + 50000 * tf_has_park\n",
    "def compute_house_price():\n",
    "    \"\"\" Computing house price using number of beds, area and has a park\"\"\"\n",
    "    tf_n_beds = tf.get_variable(\n",
    "        'n_beds', dtype=tf.float32, shape=[],\n",
    "        initializer=tf.constant_initializer(3)\n",
    "    )\n",
    "    tf_area = tf.get_variable(\n",
    "        'area', dtype=tf.float32, shape=[],\n",
    "        initializer=tf.constant_initializer(100)\n",
    "    )\n",
    "    tf_has_park = tf.get_variable(\n",
    "        'has_park', dtype=tf.float32, shape=[],\n",
    "        initializer=tf.constant_initializer(1)\n",
    "    )\n",
    "    return 10000*tf_n_beds + 5000 * tf_area + 50000 * tf_has_park\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    for _ in range(10):\n",
    "        with tf.variable_scope('house', reuse=tf.AUTO_REUSE):\n",
    "            # TODO: Call the compute_house_price function within the scope\n",
    "            tf_house_price = compute_house_price()\n",
    "        tf.global_variables_initializer().run()\n",
    "        print('My house price is {}'.format(sess.run(tf_house_price)))\n",
    "    print(\"\\nVariables in the graph\")\n",
    "    print([v.name for v in tf.global_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable 'layer_1/w:0' exists.\n",
      "Variable 'layer_1/b:0' exists.\n",
      "Variable 'layer_2/w:0' exists.\n",
      "Variable 'layer_2/b:0' exists.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope('layer_1'):\n",
    "    tf.get_variable('w', shape=[5,10], initializer=tf.initializers.random_normal(), dtype=tf.float32)\n",
    "    tf.get_variable('b', shape=[5,10], initializer=tf.initializers.random_normal(), dtype=tf.float32)\n",
    "    \n",
    "with tf.variable_scope('layer_2'):\n",
    "    tf.get_variable('w', shape=[5,10], initializer=tf.initializers.random_normal(), dtype=tf.float32)\n",
    "    tf.get_variable('b', shape=[5,10], initializer=tf.initializers.random_normal(), dtype=tf.float32)\n",
    "\n",
    "for v in tf.global_variables(): \n",
    "    print('Variable \\'{}\\' exists.'.format(v.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shape': [5, 10], 'name': 'layer1'}\n",
      "<tf.Variable 'layer1/w:0' shape=(5, 10) dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)> <tf.Variable 'layer1/b:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>\n",
      "{'shape': [10, 3], 'name': 'layer2'}\n",
      "<tf.Variable 'layer2/w:0' shape=(10, 3) dtype=float32, numpy=\n",
      "array([[0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)> <tf.Variable 'layer2/b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "layers = [{\"name\":\"layer1\", \"shape\":[5,10]}, \n",
    "          {\"name\":\"layer2\", \"shape\":[10,3]}]\n",
    "\n",
    "for layer in layers:\n",
    "\n",
    "    with tf.variable_scope(layer[\"name\"], reuse=tf.AUTO_REUSE):\n",
    "        w = tf.get_variable(\n",
    "            'w', shape=layer[\"shape\"], initializer=tf.constant_initializer())\n",
    "        b = tf.get_variable(\n",
    "            'b', shape=layer[\"shape\"][-1], initializer=tf.constant_initializer())\n",
    "\n",
    "print(tf.global_variables())\n",
    "for v in tf.global_variables(): \n",
    "    print('Variable \\'{}\\' exists.'.format(v.name))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 What happens if we don't use `sess.run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# TODO: Create a variable tf_a using \n",
    "# tf.get_variable of shape [1] and initialize with \n",
    "# tf.constant_initializer\n",
    "tf_a = tf.get_variable('a', shape=[1], initializer=tf.constant_initializer)\n",
    "# TODO: use tf.add operation to add 2 to tf_a and \n",
    "# print the result\n",
    "tf_out = tf.add(tf_a, 2)\n",
    "print(tf_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Eager execution\n",
    "Eager execution let's you to run things without building a computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restarting the Kernel \n",
    "# (Eager execution needs to be the very first thing called when a kernel stands up)\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "    tf.enable_eager_execution()\n",
    "except:\n",
    "    print(\"Is eager execution already running? {}\".format(tf.executing_eagerly()))\n",
    "    \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# TODO: Create a variable tf_a using \n",
    "# tf.get_variable of shape [1] and initialize with \n",
    "# tf.constant_initializer\n",
    "tf_a = tf.get_variable('a', shape=[1], initializer=tf.constant_initializer)\n",
    "# TODO: use tf.add operation to add 2 to tf_a and \n",
    "# print the result\n",
    "tf_out = tf.add(tf_a, 2)\n",
    "print(tf_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
